{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1b2979",
   "metadata": {},
   "source": [
    "## AI Agent Leveraging Functin Apps for Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4460933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv  \n",
    "import os  \n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "  \n",
    "# Load the .env file  \n",
    "load_dotenv(override=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb0967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "from typing import Any, Callable, Set, Dict, List, Optional\n",
    "\n",
    "def fetch_weather(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the weather information for the specified location.\n",
    "\n",
    "    :param location: The location to fetch weather for.\n",
    "    :return: Weather information as a JSON string.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"location:\", location)\n",
    "\n",
    "    import requests\n",
    "\n",
    "    url = \"https://func.azurewebsites.net/api/http_trigger\"\n",
    "    params = {\"code\": \"blah\", \"location\": location}\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    # Print the response\n",
    "    print(\"Status Code:\", response.status_code)\n",
    "    print(\"Response Body:\", response.text)\n",
    "\n",
    "    return response.text\n",
    "\n",
    "\n",
    "# Define user functions\n",
    "user_functions = {fetch_weather}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de701792",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def find_or_create_agent(agent_list, agent_name, logger):\n",
    "    agent = None\n",
    "    if agent_list:\n",
    "        async for agent_object in agent_list:\n",
    "            if agent_object.name == agent_name:\n",
    "                agent = agent_object\n",
    "                logger.info(f\"Found agent by name '{agent_name}', ID={agent_object.id}\")\n",
    "                return agent\n",
    "    \n",
    "        if not agent:\n",
    "            logger.info(f\"Agent with name '{agent_name}' not found, creating a new agent.\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede18783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.agents.models import FunctionTool\n",
    "from azure.ai.agents.models import FunctionTool, ToolSet, ListSortOrder\n",
    "import logging\n",
    "import asyncio\n",
    "\n",
    "\n",
    "# Configure logger\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(\"notebook_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Clear existing handlers to avoid duplicate logs\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "# Create handler that outputs to notebook\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Example usage\n",
    "logger.info(\"Logger is now printing to the notebook!\")\n",
    "\n",
    "\n",
    "\n",
    "# Retrieve the project endpoint from environment variables\n",
    "project_endpoint = os.environ[\"PROJECT_ENDPOINT\"]\n",
    "\n",
    "# Initialize the AIProjectClient\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=project_endpoint,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "os.environ['AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED'] = 'true'\n",
    "# Enable Azure Monitor tracing\n",
    "application_insights_connection_string = project_client.telemetry.get_connection_string()\n",
    "\n",
    "logger.info(f\"Application Insights connection string: {application_insights_connection_string}\")\n",
    "\n",
    "if not application_insights_connection_string:\n",
    "    print(\"Application Insights was not enabled for this project.\")\n",
    "    print(\"Enable it via the 'Tracing' tab in your Azure AI Foundry project page.\")\n",
    "    exit()\n",
    "    \n",
    "configure_azure_monitor(connection_string=application_insights_connection_string)\n",
    "\n",
    "agent_name = os.environ[\"AZURE_AI_AGENT_NAME\"]\n",
    "agent_list = project_client.agents.list_agents()\n",
    "\n",
    "agent = None\n",
    "if agent_list:\n",
    "    for agent_object in agent_list:\n",
    "        if agent_object.name == agent_name:\n",
    "            agent = agent_object\n",
    "\n",
    "if not agent:\n",
    "    logger.info(f\"Agent with name '{agent_name}' not found, creating a new agent.\")\n",
    "    functions = FunctionTool({fetch_weather})\n",
    "    toolset = ToolSet()\n",
    "    toolset.add(functions)\n",
    "    project_client.agents.enable_auto_function_calls(toolset)\n",
    "\n",
    "        # Create an agent with custom functions\n",
    "\n",
    "    agent = project_client.agents.create_agent(\n",
    "            model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "            name=agent_name,\n",
    "            instructions=\"You are a helpful agent with tools to fetch weather information.\",\n",
    "            tools=functions.definitions,\n",
    "        )\n",
    "    logger.info(f\"Created agent, ID: {agent.id}\")\n",
    "else:\n",
    "    logger.info(f\"Found agent by name '{agent_name}', ID={agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = project_client.agents.threads.create()\n",
    "print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "# Create message to thread\n",
    "message = project_client.agents.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",  # Role of the message sender\n",
    "        content=\"what is the weather in London?\",  # Message content\n",
    "    )\n",
    "print(f\"Created message, ID: {message['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aca495",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "print(agent.name)\n",
    "print(agent.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee003511",
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb63c45",
   "metadata": {},
   "source": [
    "## View your Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1103f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "    \n",
    "# Fetch and log all messages\n",
    "messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "for message in messages:\n",
    "    print(f\"Role: {message.role}, Content: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68c23f3",
   "metadata": {},
   "source": [
    "## View your Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ce374",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = project_client.agents.run_steps.list(thread_id=thread.id, run_id=run.id)\n",
    "for step in run_steps:\n",
    "        # print(f\"Step {step['id']} status: {step['status']}\")\n",
    "        step_details = step.get(\"step_details\", {})\n",
    "        tool_calls = step_details.get(\"tool_calls\", [])\n",
    "\n",
    "        if tool_calls:\n",
    "            print(\"  Tool calls:\")\n",
    "            for call in tool_calls:\n",
    "                print(call)\n",
    "                print(f\"    Tool Call ID: {call.get('id')}\")\n",
    "                print(f\"    Type: {call.get('type')}\")\n",
    "                type = call.get(\"type\")\n",
    "                if type == \"function\":\n",
    "                    print(f\"    Function Name: {call.get('function', {}).get('name')}\")\n",
    "                    print(f\"    Function Arguments: {call.get('function', {}).get('arguments')}\")\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import CoherenceEvaluator, AzureOpenAIModelConfiguration\n",
    "\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "        azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_KEY\"),\n",
    "        azure_deployment=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "        api_version=os.environ.get(\"AZURE_API_VERSION\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5089cddc",
   "metadata": {},
   "source": [
    "## Check Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d68581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract user and agent messages for coherence evaluation\n",
    "coherence = CoherenceEvaluator(model_config=model_config, threshold=3)\n",
    "user_message = None\n",
    "agent_message = None\n",
    "messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "for message in messages:\n",
    "    print(message.role)\n",
    "    if str(message.role) == \"MessageRole.USER\" and user_message is None:\n",
    "        user_message = message.content\n",
    "    elif str(message.role) in (\"MessageRole.AGENT\") and agent_message is None:\n",
    "        agent_message = message.content\n",
    "\n",
    "if user_message and agent_message:\n",
    "    print(\"checking coherence\")\n",
    "    coherence_score = coherence(query=user_message, response=agent_message)\n",
    "    print(f\"Coherence score: {coherence_score}\")\n",
    "else:\n",
    "    print(\"Could not find both user and agent messages for coherence evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73329b4a",
   "metadata": {},
   "source": [
    "## Check Intent Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3540775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import IntentResolutionEvaluator\n",
    "\n",
    "intent_resolution = IntentResolutionEvaluator(model_config=model_config, threshold=3)\n",
    "intent_resolution(\n",
    "    query=user_message,\n",
    "    response=agent_message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a44fdcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "176145c8",
   "metadata": {},
   "source": [
    "## QA Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da94a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import QAEvaluator\n",
    "\n",
    "qa_eval = QAEvaluator(model_config=model_config, threshold=3)\n",
    "qa_eval(\n",
    "    query=\"Where was Marie Curie born?\", \n",
    "    context=\"Background: 1. Marie Curie was a chemist. 2. Marie Curie was born on November 7, 1867. 3. Marie Curie is a French scientist.\",\n",
    "    response=\"According to wikipedia, Marie Curie was not born in Paris but in Warsaw.\",\n",
    "    ground_truth=\"Marie Curie was born in Warsaw.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7986f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
