{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1001865e",
   "metadata": {},
   "source": [
    "## AI Search Agent\n",
    "\n",
    "- Search Quickstart: https://github.com/Azure-Samples/azure-search-python-samples/blob/main/Quickstart/azure-search-quickstart.ipynb\n",
    "\n",
    "\n",
    "- https://github.com/Azure-Samples/azure-search-python-samples/blob/main/agentic-retrieval-pipeline-example/agent-example.ipynb\n",
    "\n",
    "- Getting started with Agents: https://github.com/Azure-Samples/get-started-with-ai-agents\n",
    "\n",
    "- Cool Agent Templates: https://github.com/azure-ai-foundry/foundry-samples/blob/main/samples/agent-catalog/msft-agent-samples/foundry-agent-service-sdk/meeting-prep-agent/python/template.py\n",
    "\n",
    "- Adding a `Vectorizer` https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-configure-vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8733528d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a2f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# The following variables from your .env file are used in this notebook\n",
    "project_endpoint = os.environ[\"PROJECT_ENDPOINT\"]\n",
    "agent_model = os.getenv(\"AGENT_MODEL\", \"gpt-4.1-mini\")\n",
    "endpoint = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://search.azure.com/.default\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX\", \"earth_at_night\")\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_gpt_deployment = os.getenv(\"AZURE_OPENAI_GPT_DEPLOYMENT\", \"gpt-4.1-mini\")\n",
    "azure_openai_gpt_model = os.getenv(\"AZURE_OPENAI_GPT_MODEL\", \"gpt-4.1-mini\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "azure_openai_embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-large\")\n",
    "agent_name = os.getenv(\"AZURE_SEARCH_AGENT_NAME\", \"earth-search-agent\")\n",
    "api_key = os.getenv(\"AZURE_SEARCH_API_KEY\", None)\n",
    "\n",
    "# # Check for empty environment variables and print a message if any are empty\n",
    "variables = [\n",
    "    (\"PROJECT_ENDPOINT\", project_endpoint),\n",
    "    (\"AGENT_MODEL\", agent_model),\n",
    "    (\"AZURE_SEARCH_ENDPOINT\", endpoint),\n",
    "    (\"AZURE_SEARCH_INDEX\", index_name),\n",
    "    (\"AZURE_OPENAI_ENDPOINT\", azure_openai_endpoint),\n",
    "    (\"AZURE_OPENAI_GPT_DEPLOYMENT\", azure_openai_gpt_deployment),\n",
    "    (\"AZURE_OPENAI_GPT_MODEL\", azure_openai_gpt_model),\n",
    "    (\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", azure_openai_embedding_deployment),\n",
    "    (\"AZURE_OPENAI_EMBEDDING_MODEL\", azure_openai_embedding_model),\n",
    "    (\"AZURE_SEARCH_AGENT_NAME\", agent_name),\n",
    "    (\"AZURE_SEARCH_API_KEY\", api_key),\n",
    "]\n",
    "\n",
    "for var_name, value in variables:\n",
    "    if not value:\n",
    "        print(f\"Environment variable '{var_name}' is empty or not set.\")\n",
    "    else:\n",
    "        print(f\"Environment variable '{var_name}' is set to: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c2d2f",
   "metadata": {},
   "source": [
    "## Create an index on Azure AI Search.\n",
    "\n",
    "This steps create a search index that contains plain text and vector content. You can use any existing search index, but it must meet the criteria for agentic retrieval workloads. The primary schmea requirement is that is has a semantic configuration, with a `default_configuration_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf3f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import SearchIndex, SearchField, VectorSearch, VectorSearchProfile, HnswAlgorithmConfiguration, AzureOpenAIVectorizer, AzureOpenAIVectorizerParameters, SemanticSearch, SemanticConfiguration, SemanticPrioritizedFields, SemanticField\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=[\n",
    "        SearchField(name=\"id\", type=\"Edm.String\", key=True, filterable=True, sortable=True, facetable=True),\n",
    "        SearchField(name=\"page_chunk\", type=\"Edm.String\", filterable=False, sortable=False, facetable=False),\n",
    "        SearchField(name=\"page_embedding_text_3_large\", type=\"Collection(Edm.Single)\", stored=True, vector_search_dimensions=3072, vector_search_profile_name=\"hnsw_text_3_large\"),\n",
    "        SearchField(name=\"page_number\", type=\"Edm.Int32\", filterable=True, sortable=True, facetable=True)\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        profiles=[VectorSearchProfile(name=\"hnsw_text_3_large\", algorithm_configuration_name=\"alg\", vectorizer_name=\"azure_openai_text_3_large\")],\n",
    "        algorithms=[HnswAlgorithmConfiguration(name=\"alg\")],\n",
    "        vectorizers=[\n",
    "            AzureOpenAIVectorizer(\n",
    "                vectorizer_name=\"azure_openai_text_3_large\",\n",
    "                parameters=AzureOpenAIVectorizerParameters(\n",
    "                    resource_url=azure_openai_endpoint,\n",
    "                    deployment_name=azure_openai_embedding_deployment,\n",
    "                    model_name=azure_openai_embedding_model\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semantic_config\",\n",
    "        configurations=[\n",
    "            SemanticConfiguration(\n",
    "                name=\"semantic_config\",\n",
    "                prioritized_fields=SemanticPrioritizedFields(\n",
    "                    content_fields=[\n",
    "                        SemanticField(field_name=\"page_chunk\")\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_index(index)\n",
    "print(f\"Index '{index_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c143231e",
   "metadata": {},
   "source": [
    "## Upload sample docs\n",
    "This sample uses data from NASA's Earch at Night e-book.  It's retrieved from the sample GitHub repository and passed to the search client for idexig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ac06d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/refs/heads/main/nasa-e-book/earth-at-night-json/documents.json\"\n",
    "documents = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "# Define your service and index details\n",
    "\n",
    "credential = AzureKeyCredential(api_key)\n",
    "# Create a client\n",
    "index_client = SearchClient(endpoint=endpoint, credential=credential, index_name=index_name)\n",
    "\n",
    "result = index_client.upload_documents(documents=documents)\n",
    "print(\"Upload result:\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10d44a0",
   "metadata": {},
   "source": [
    "## Create an AI Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b8f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(azure_openai_endpoint)\n",
    "print(azure_openai_gpt_deployment)\n",
    "print(azure_openai_gpt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2145a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import KnowledgeAgent, KnowledgeAgentAzureOpenAIModel, KnowledgeAgentTargetIndex, KnowledgeAgentRequestLimits, AzureOpenAIVectorizerParameters\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "agent = KnowledgeAgent(\n",
    "    name=agent_name,\n",
    "    models=[\n",
    "        KnowledgeAgentAzureOpenAIModel(\n",
    "            azure_open_ai_parameters=AzureOpenAIVectorizerParameters(\n",
    "                resource_url=azure_openai_endpoint,\n",
    "                deployment_name=azure_openai_gpt_deployment,\n",
    "                model_name=azure_openai_gpt_model\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    target_indexes=[\n",
    "        KnowledgeAgentTargetIndex(\n",
    "            index_name=index_name,\n",
    "            default_reranker_threshold=2.5\n",
    "        )\n",
    "    ],\n",
    "    request_limits=KnowledgeAgentRequestLimits(\n",
    "        max_output_size=10000\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_agent(agent)\n",
    "print(f\"Knowledge agent '{agent_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "credential = DefaultAzureCredential()\n",
    "print(project_endpoint)\n",
    "project_client = AIProjectClient(endpoint=project_endpoint, credential=credential)\n",
    "\n",
    "list(project_client.agents.list_agents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "A Q&A agent that can answer questions about the Earth at night.\n",
    "Sources have a JSON format with a ref_id that must be cited in the answer using the format [ref_id].\n",
    "If you do not have the answer, respond with \"I don't know\".\n",
    "\"\"\"\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=agent_model,\n",
    "    name=agent_name,\n",
    "    instructions=instructions\n",
    ")\n",
    "\n",
    "print(f\"AI agent '{agent_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a1f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import FunctionTool, ToolSet, ListSortOrder\n",
    "\n",
    "from azure.search.documents.agent import KnowledgeAgentRetrievalClient\n",
    "from azure.search.documents.agent.models import KnowledgeAgentRetrievalRequest, KnowledgeAgentMessage, KnowledgeAgentMessageTextContent, KnowledgeAgentIndexParams\n",
    "\n",
    "agent_client = KnowledgeAgentRetrievalClient(endpoint=endpoint, agent_name=agent_name, credential=credential)\n",
    "\n",
    "thread = project_client.agents.threads.create()\n",
    "retrieval_results = {}\n",
    "\n",
    "def agentic_retrieval() -> str:\n",
    "    \"\"\"\n",
    "        Searches a NASA e-book about images of Earth at night and other science related facts.\n",
    "        The returned string is in a JSON format that contains the reference id.\n",
    "        Be sure to use the same format in your agent's response\n",
    "        You must refer to references by id number\n",
    "    \"\"\"\n",
    "    # Take the last 5 messages in the conversation\n",
    "    messages = project_client.agents.messages.list(thread.id, limit=5, order=ListSortOrder.DESCENDING)\n",
    "    # Reverse the order so the most recent message is last\n",
    "    messages = list(messages)\n",
    "    messages.reverse()\n",
    "    retrieval_result = agent_client.retrieve(\n",
    "        retrieval_request=KnowledgeAgentRetrievalRequest(\n",
    "            messages=[KnowledgeAgentMessage(role=msg[\"role\"], content=[KnowledgeAgentMessageTextContent(text=msg.content[0].text)]) for msg in messages if msg[\"role\"] != \"system\"],\n",
    "            target_index_params=[KnowledgeAgentIndexParams(index_name=index_name, reranker_threshold=2.5)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Associate the retrieval results with the last message in the conversation\n",
    "    last_message = messages[-1]\n",
    "    retrieval_results[last_message.id] = retrieval_result\n",
    "\n",
    "    # Return the grounding response to the agent\n",
    "    return retrieval_result.response[0].content[0].text\n",
    "\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/function-calling\n",
    "functions = FunctionTool({ agentic_retrieval })\n",
    "toolset = ToolSet()\n",
    "toolset.add(functions)\n",
    "project_client.agents.enable_auto_function_calls(toolset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e216a8bd",
   "metadata": {},
   "source": [
    "## Start Chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd1b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import AgentsNamedToolChoice, AgentsNamedToolChoiceType, FunctionName\n",
    "\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"\"\"\n",
    "        Why do suburban belts display larger December brightening than urban cores even though absolute light levels are higher downtown?\n",
    "        Why is the Phoenix nighttime street grid is so sharply visible from space, whereas large stretches of the interstate between midwestern cities remain comparatively dim?\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "run = project_client.agents.runs.create_and_process(\n",
    "    thread_id=thread.id,\n",
    "    agent_id=agent.id,\n",
    "    tool_choice=AgentsNamedToolChoice(type=AgentsNamedToolChoiceType.FUNCTION, function=FunctionName(name=\"agentic_retrieval\")),\n",
    "    toolset=toolset)\n",
    "if run.status == \"failed\":\n",
    "    raise RuntimeError(f\"Run failed: {run.last_error}\")\n",
    "output = project_client.agents.messages.get_last_message_text_by_role(thread_id=thread.id, role=\"assistant\").text.value\n",
    "\n",
    "print(\"Agent response:\", output.replace(\".\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33918064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import AzureAISearchTool, AzureAISearchQueryType\n",
    "from azure.ai.projects.models import ConnectionType\n",
    "\n",
    "# Define the Azure AI Search connection ID and index name\n",
    "azure_ai_conn_id = project_client.connections.get_default(ConnectionType.AZURE_AI_SEARCH).id\n",
    "\n",
    "# find the index name in your AI Search Azure resource page under Search Management -> Indexes\n",
    "index_name = \"mmxindex01\"\n",
    "\n",
    "# Initialize the Azure AI Search tool\n",
    "ai_search = AzureAISearchTool(\n",
    "    index_connection_id=azure_ai_conn_id,\n",
    "    index_name=index_name,\n",
    "    query_type=AzureAISearchQueryType.SIMPLE,  # Use SIMPLE query type\n",
    "    top_k=3,  # Retrieve the top 3 results\n",
    "    filter=\"\",  # Optional filter for search results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148da803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model deployment name\n",
    "model_deployment_name = os.environ[\"AGENT_MODEL\"]\n",
    "\n",
    "# Create an agent with the Azure AI Search tool\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=model_deployment_name,\n",
    "    name=\"my-agent\",\n",
    "    instructions=\"You are a helpful agent\",\n",
    "    tools=ai_search.definitions,\n",
    "    tool_resources=ai_search.resources,\n",
    ")\n",
    "print(f\"Created agent, ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c049e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import MessageRole, ListSortOrder\n",
    "\n",
    "# Create a thread for communication\n",
    "thread = project_client.agents.threads.create()\n",
    "print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "# Send a message to the thread\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=MessageRole.USER,\n",
    "    content=\"Why do suburban belts display larger December brightening than urban cores even though absolute light levels are higher downtown?\",\n",
    ")\n",
    "print(f\"Created message, ID: {message['id']}\")\n",
    "\n",
    "# Create and process a run with the specified thread and agent\n",
    "run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "# Check if the run failed\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# Fetch and log all messages in the thread\n",
    "messages = project_client.agents.messages.list(thread_id=thread.id, order=ListSortOrder.ASCENDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5d5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in messages:\n",
    "    print(f\"Message ID: {m['id']}, Role: {m['role']}, Content: {m.content[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb9c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=MessageRole.USER,\n",
    "    content=\"How do I find lava at night? Use the retrieval tool to answer this question\",\n",
    ")\n",
    "\n",
    "run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "\n",
    "# print(\"Agent response:\", output.replace(\".\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea33b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the run failed\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# Fetch and log all messages in the thread\n",
    "messages = project_client.agents.messages.list(thread_id=thread.id, order=ListSortOrder.ASCENDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b3889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in messages:\n",
    "    print(f\"Message ID: {m['id']}, Role: {m['role']}, Content: {m.content[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91553c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = project_client.agents.run_steps.list(thread_id=thread.id, run_id=run.id)\n",
    "for step in run_steps:\n",
    "        print(f\"Step {step['id']} status: {step['status']}\")\n",
    "        step_details = step.get(\"step_details\", {})\n",
    "        tool_calls = step_details.get(\"tool_calls\", [])\n",
    "\n",
    "        if tool_calls:\n",
    "            print(\"  Tool calls:\")\n",
    "            for call in tool_calls:\n",
    "                print(f\"    Tool Call ID: {call.get('id')}\")\n",
    "                print(f\"    Type: {call.get('type')}\")\n",
    "\n",
    "                azure_ai_search_details = call.get(\"azure_ai_search\", {})\n",
    "                if azure_ai_search_details:\n",
    "                    print(f\"    azure_ai_search input: {azure_ai_search_details.get('input')}\")\n",
    "                    print(f\"    azure_ai_search output: {azure_ai_search_details.get('output')}\")\n",
    "        print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496d14fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a0786c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
